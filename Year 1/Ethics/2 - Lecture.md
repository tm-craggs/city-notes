**The ethical concerns of engineers**
- Military Use - Is my work going to used to kill people?
- Privacy - Is my work used to collect peoples personal location and information without their consent or to misuse their data without their knowledge. 
- Advertising - Am I contributing to spam? Am I inaccurately or unfairly classifying people for advertising purposes? Am I designing misleading or dishonest interfaces. 
- Surveillance - Is my work used to spy on workers or civilians? 


Other considerations

- Environmental Impact
- Causing unemployment
- Contributing to crypto scams
- Political manipulation
- Inaccessible software
- etc.

Common harms for technology users
- Dishonesty and untruth - the spread of false information about people, events, relationships, etc (e.g. gaslight, fake news).
- Harm and Hate - Trolling, cyber-bullying
- Discrimination - Racism, misogyny
- Manipulation - Using false information to sway people opinions
- Fraud - Phising, social maniupulation

How do engineers respond ethical concerns

Negotiation - Convincing decision-makers to take action by highlighting negative 
Feet voting - Refusing offers of employment, not applying for certain jobs, collective bargaining and tech worker boycotts
Refusal - Reducing one's productivity asking to be assigned to a different project, resigning


Resignation
- Engineers should not have to resign from their jobs, it should be used as a last resort.
- Engineers resign because they lose faith in their employers and feel powerless to change
- It is ineffective, a new developer is usually hired who agrees to do the questionable work. 
- Not everyone can resign, engineers on visas, or people who are financially unstable. 
- We need new ways of dealing with ethical concerns. 

"Grounded" Ethics

- A grounded perspective addresses ethics through real-world experiences and examples
- By "grounded" we mean understanding the implications of the systems we build, and considering the specific circumstances that surround them. 
- Grounded ethics implies that a concern for ethics and the societal impact of digital technologies is an integral and unavoidable part of software engineering professional practise. 
- A grounded ethics requires tools to help us think

Tools for grounded ethics

- Speculative ethics
- The FAPT (Fairness, accountability, privacy, transparency) framework
- Professional codes of conduct


**Speculative Ethics**

- Speculation - using imagination to anticipate the potential benefits and harms of a technology
- Speculation helps you forsee the consequences of emerging technologies
- Speculation can help mitigate the negative outcomes of emerging technologies
- Conclusion can sometimes be that the technology should not be built at all

- Examples speculation:
	- What could go wrong with this technology?
	- What is something happened?
	- Could this technology be used to cause harm?
	- Why would society agree to use this technology?

Ethical example:

A dating site for cheating - Ashley Madison hack

**The FAPT framework**

![[Pasted image 20250204120608.png]]

**Fairness**
- Our technologies must respect the dignity of individuals, and be consistent with the public interests. (Human rights, democratic values)
- Our technologies must not discriminate against certain individuals or social groups. 
- We must mitigate against biases the may influence our technologies outcomes. 
**Accountability**
- We must consider who is responsible for computing systems and their outcomes.
- There must be effective decision-making and oversight mechanisms for any technology. E.g. Who is responsible for the content that users publish on social media. 
**Privacy**
- Technologies must respect and safeguard the privacy of individuals
- Technologies must comply with privacy law (UK GDPR)
**Transparency**
- Actions, processes and data must be open to inspection by publishing information about the technology in a complete, open, understandable, easily accessible and free format. 
- Transparency supports accountability
- E.g. Show data that was used to train an AI model.

**Step 1: Who May Be Affected?**
- Consider who might be affected by the technology (stakeholders)
- Who might be affected positively?
- Who might be affected negatively?
- Look at this across all four dimensions (FAPT)
- Look across different scales (individuals, groups, governments, nations, natural environments, etc.)
**Step 2: What are the potential impacts?**
- What are the consequences of the technology for each of the stakeholders you indentified in step 1?
- How might their privacy, dignity and other rights be comprimised?
- Will they be prevented from accessing material resources?
- Will their reputation be damaged?
- Think short term, long term, local, global and environmental. 
- Consider historical factors / injustrices that may not be obvious. (racially or gender biased algorithms)
**Step 3: How can risk be addressed?**