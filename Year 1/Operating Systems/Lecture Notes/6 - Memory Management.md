
## Background and Introduction

- Memory wish list:
	- Private
	- Infinitely large
	- Infinitely fast
	- Non-volatile (holds data when turned off)
	- Inexpensive
- This is obviously not possible, but gives an idea about what we try to achieve with Computer Memory
- This is why memory hierarchy exists, as different types of memory are good at achieving different things. For example:
	- **Cache Memory** - Fast, but small and expensive
	- **Solid State** - Slow, but large, cheap and non-volatile
	- **Main Memory** - Middle ground, decent speed and price, but is volatile 

**Memory Hierarchy**
- Program must be brought from disk into memory and placed within a process for it to run. 
- Main memory and registers are only storage CPU can access directly. 
- Register access in one or less CPU clock
- Main memory can takes many cycles to access, causing a CPU stall
- Cache sits between main memory and CPU registers. 

**Principle of locality**
- The principle of locality states that programs access a relatively small portion of their address space at any instant of time
- There are 2 types of locality
	- **Temporal Locality** (locality in time) - If an item is referenced, it will tend to be referenced again soon. 
	- **Spatial locality** (locality in space) - If an item is referenced, items whose addresses are close by will tend to be referenced soon. Imagine books on the same shelf. 

**Taking advantage of locality** 
- Store everything somewhere where it is cheap, although slow to access. 
- Copy recently accessed and nearby items from disk to smaller DRAM memory (main memory)
- Copy more recently accessed (and nearby) items from DRAM to smaller SRAM memory (Cache memory)

**Memory Manager**

- The memory manager must manage all the memory resources, which parts are in use, and allocate and free memory as necessary. 
- To improve CPU performance and speed, we must keep several processes in memory. 
## Memory Abstraction

- To better understand a complex process, we can simplify and remove as many unnecessary details and keep only the most important attributes. 
- For example: "bits" in memory are actually flip-flop logic gate circuits, but this detail is not crucial, we can simply represent them as 1s or 0s. 

## Address Space

**Logical vs. Physical Address Space**

- The concept of a logical address space that is bound to a separate **physical address space** is central to proper memory management. 
- **Logical Address** - Generated by the CPU, can also be called **virtual address** 
- **Physical address** - Address seen by the memory unit. 

- Logical and physical addresses are the same in compile-time and load-time address-binding schemes.
- Logical and physical addresses differ in execution-time address-binding scheme
- **Logical address space** - The set of all logical addresses generated by a program
- **Physical address space** - The set of all physical addresses generated by a program. 

**Virtual Memory**

- Virtual memory creates memory space on the hard drive when main memory is full.
- The process of moving blocks of memory around like this is called Memory Mapping.

**Context Switching**

- Switching the CPU to another process requires performing a state save of the current process and a state restore of a different process.
- This task is known as a **context switch**. When a context switch occurs, the kernel saves the old process in its PCB (Process Control Block) and loads the saved context of the new process scheduled to run. 
## Memory Management Unit (MMU)

-  Hardware device that at run time maps virtual to physical address, there are many methods possible. 
- The user program deals with logical addresses, it never sees the real physical addresses.
	- Execution-time binding occurs when reference is made to location in memory. 
	- Logical address bound to physical addresses.
- Consider a simple scheme where the value in the relocation register is added to every address generated by a user process at the time it is sent to memory. 
	- Base register is now called **relocation register**
- The value in the relocation register is added to every address generated by a user process at the time the address is sent to memory. 

**Dynamic Relocation using a relocation register**

![[Pasted image 20250407125929.png]]

- When a context switch occurs, the register is updates and the new address is generated. 

**Protection**

- The OS needs to prevent processes from accessing one another's memory. 
	- Using a system call for each memory address would be hopelessly slow
	- The MMU needs to play a role. 
- Simple dynamic relocation does not provide memory protection. A limit register is needed.

**Dynamic relocation using a relocation and limit register**

![[Pasted image 20250407130222.png]]

**Logical Address Space**

- A pair of base and limit registers define the logical address space. 
- The CPU must check every memory access generated in user mode to be sue it is between the base and limit for that user. 

**Hardware Address Protection**

- CPU must check every memory access generated in user mode to be sure it is between base and limit for that user. 

![[Pasted image 20250407130810.png]]



## Larger Processes: Virtual Memory, Swapping

- A process needs to be loaded in memory to be executed
- If the physical memory is large enough, things are fine. 
- If not...

![[Pasted image 20250407131116.png]]

**Swapping**

- May not be enough physical memory to hold all the current processes at the same time, but only one process is actually on the CPU at a time. 
- A process can be swapped temporarily out of memory to a backing store, and then brought back into memory for continued execution. 
- The largest part of swap time is **disk read/write** time. The total transfer time is proportional to the amount of memory swapped. 
- Modified versions of swapping are found on most OS
- Bring in each entire process, run for a while, then put it back on the disk. 
- Idle processes are mostly stored on disk, so they do not take up any memory when they are not running. 

**Context Switch Time including swapping** 

- If next processes to be put on CPU is not in memory, need to swap out a process and swap in target processes.
- Context switch time can be very high in this scenario. 
- Exercise: For a process of 100MB swapping to hard disk with a transfer rate of 50MB/sec, calculate:

**Latency**

- The largest part of swap time is disk read/write time. Less significant is latency. 
- The total transfer time is proportional to the amount of memory swapped.
- If latency = 8 nano seconds, what is the total swapping time?

**Slowdown factor**

- Sometimes processes run as fast as possible, but not always. Slowdown factor calculates the ration of the slow case over the fast case.
- Slowdown = t-slow / t-fast

**Priority Processes**

- If a higher-priority process arrives and wants service, the memory manager can swap out the lower-priority process and then load and execute the higher-priority process.
- When the higher-priority process finishes, the lower priority process can be swapped back. 
- This variant of swapping is sometimes called roll-in, roll-out. 
- Whether or not the swapped out process needs to be swapped back into the same physical addresses depends on binding method. 

**Context Switch Time including Swapping**

- Can reduce if reduce size of memory swapped - by knowing how much memory is being used.
	- System calls to inform OS of memory use via ``request_memory()`` and ``release memory()`` 
- Standard swapping not used in modern operating systems, but modified versions are common. 
	- Swap only when free memory extremely low. 
- Other constraints on swapping
	- Pending I/O - Can't swap out as I/O would occur to wrong process.
	- Or always transfer I/O to kernel space (double buffering) - Adds overhead

**Swapping on Mobile Systems**

- Not typically supported
	- Flash memory based:
		- Small amount of space
		- Limited number of write cycles
		- Poor throughput between flash memory and CPU on mobile platform. 
- Instead use other methods to free memory if low. 
	- iOS asks apps to voluntarily relinquish allocated memory
		- Read-only data thrown out and reloaded from flash if needed. 
		- Failure to free can result in termination. 
	- Android terminates apps if low free memory, but first writes its application state to flash for fast restart. 
- Both support paging. 

**Contiguous Allocation**

- Main memory must support both OS and user processes. 
- Limited resource, must allocate efficiently. 
- Contiguous allocation is one early method. 
- Main memory usually in two partitions
	- Resident OS, usually held in low memory with interrupt vector
	- User processes then held in high memory. 
	- Each process contained in single contiguous section of memory

**Room for growth**

- How much memory should be allocated for a process when it is created or swapped in. 
- If the processes is fixed, this is easy. 
- If the process can grow
	- If the is a hole adjacent, allocate and grow in the hole. 
	- If there is no memory to grow, suspend and wait, or kill it. 
- Or allocate some space so that the process can grow. 

**Dynamic Storage-Allocation Problem**

- How to satisfy a request of size n, from a list of free holes?
- **First fit** - Allocate the first hole that is big enough. 
	- Find a hole that is big enough for the process.
	- Hole is divided into one section for the process and the free space, if any. 
	- Fast algorithm as it searches as little as possible. 
- **Best fit** - Allocate the smallest hole that is big enough. 
	- Must search entire list, unless ordered by size. And use the smallest hole that is adequate. 
	- Rather than breaking up a big hole that may be needed later.
	- Best fit is slower than first fit as it needs to search. 
	- It also produces the smallest leftover hole, which, being tiny, tends to be useless. 
- **Worst fit** - Allocate the largest hole, must also search the entire list
	- Produces the largest leftover hole. 
	- First fit and best fit are better in terms of speed and storage utilisation. 


**External Fragmentation**

- Both first-fit and best-fir will suffer from external fragmentation. 
- As processes are loaded/removed, free memory space is divided into little pieces. 
- External fragmentation exists when there is enough space to satisfy a request, but the available space is not contiguous. 
- i.e. Storage is fragmented into a large number of small holes. 

**Internal Fragmentation**

- Example: A partition allocation with a hole of 18,000 bytes. Next process requests 17,998. 
- A hole of 2 bytes will be useless, and the overhead to keep record of the hole is larger than those 2 bytes.
- Use fixed size block instead, which may have some unused space.
- So the process will just be allocated the full 18,000 bytes. It is more simple. 

**Fragmentation**

- External Fragmentation - Total memory space exists to satisfy a request, but it is not contiguous. 
- Internal Fragmentation - Allocated memory may be slightly larger than requested memory, this size difference is memory internal to a partition, but not being used. 
- First fit analysis reveals that given n blocks allocated, 0.5 n blocks are lost to fragmentation. 
- 1/3rd may be unusable, 50% rule. 
- Reduce external fragmentation by **compaction** 
	- Shuffle memory contents to place all free memory together in one large block. 
	- Compaction is possible only if relocation is du

## Paging



## Page Replacement
